{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannisthamaiti/AIWeekend-Project/blob/main/Transformer/Transformer_chatbot_complex_movie_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBbUJEFwbZ4V",
        "outputId": "8f652a89-99ff-46b0-a631-cbbbb7be00d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2025-05-14 20:44:58--  https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.53\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‚Äòcornell_movie_dialogs_corpus.zip‚Äô\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  10.7MB/s    in 0.9s    \n",
            "\n",
            "2025-05-14 20:45:00 (10.7 MB/s) - ‚Äòcornell_movie_dialogs_corpus.zip‚Äô saved [9916637/9916637]\n",
            "\n",
            "replace cornell movie-dialogs corpus/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/cornell movie-dialogs corpus/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/chameleons.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/movie_characters_metadata.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/movie_titles_metadata.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/raw_script_urls.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/cornell movie-dialogs corpus/._README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "mkdir: cannot create directory ‚Äòdatasets‚Äô: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch transformers\n",
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
        "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
        "!rm cornell_movie_dialogs_corpus.zip\n",
        "!mkdir datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "\n",
        "This tutorial trains a Transformer model to be a chatbot. This is an advanced example that assumes knowledge of text generation, attention and transformer.\n",
        "\n",
        "We will use the conversations in movies and TV shows provided by Cornell Movie-Dialogs Corpus, which contains more than 220 thousands conversational exchanges between more than 10k pairs of movie characters, as our dataset.\n",
        "\n",
        "movie_conversations.txt contains list of the conversation IDs and movie_lines.text contains the text of assoicated with each conversation ID. For further information regarding the dataset, please check the README file in the zip file."
      ],
      "metadata": {
        "id": "v5pnboqLbvJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import math\n"
      ],
      "metadata": {
        "id": "rrrHwFJOdAzi"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax()\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset ## We'll store our data in DataLoaders\n",
        "from torch.optim import Adam\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "izzM6fe_oUnr"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(string):\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punct = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char  # space is also a character\n",
        "    return no_punct.lower()"
      ],
      "metadata": {
        "id": "wG-lPDUJcQWu"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "max_len = 25\n",
        "\n",
        "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
        "corpus_movie_lines = './datasets/movie_lines.txt'\n",
        "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
        "    conv = c.readlines()\n",
        "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
        "    lines = l.readlines()\n",
        "\n",
        "# extract text\n",
        "lines_dic = {}\n",
        "for line in lines:\n",
        "    objects = line.split(\" +++$+++ \")\n",
        "    lines_dic[objects[0]] = objects[-1]"
      ],
      "metadata": {
        "id": "aeOfqGIvbtiS"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate question answer pairs\n",
        "pairs = []\n",
        "for con in conv:\n",
        "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        if i == len(ids) - 1:\n",
        "            break\n",
        "\n",
        "        first = remove_punc(lines_dic[ids[i]].strip())\n",
        "        second = remove_punc(lines_dic[ids[i+1]].strip())\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        pairs.append(qa_pairs)\n",
        "\n",
        "# sample\n",
        "print(pairs[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XagHo-TccGk",
        "outputId": "9c431a4b-810e-47ba-c18a-8e37f54213a2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding"
      ],
      "metadata": {
        "id": "t_Mr4nfjc2vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word map\n",
        "min_word_freq = 5\n",
        "\n",
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "    word_freq.update(pair[0])\n",
        "    word_freq.update(pair[1])\n",
        "\n",
        "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "word_map['<unk>'] = len(word_map) + 1\n",
        "word_map['<start>'] = len(word_map) + 1\n",
        "word_map['<end>'] = len(word_map) + 1\n",
        "word_map['<pad>'] = 0\n",
        "\n",
        "print(\"Total words are: {}\".format(len(word_map)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DwFdaN3crWj",
        "outputId": "bc90af23-d138-4f11-f5c9-2027f49d3e73"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words are: 18243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "# encode sentences based on word map\n",
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply_input(words, word_map):\n",
        "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "\n",
        "pairs_encoded = []\n",
        "for pair in pairs:\n",
        "    qus = encode_question(pair[0], word_map)\n",
        "    ans_input = encode_reply_input(pair[1], word_map)\n",
        "    ans = encode_reply(pair[2], word_map)\n",
        "    if len(qus) == 25 and len(ans_input) == 25 and len(ans) == 25:\n",
        "      pairs_encoded.append([qus, ans_input,ans])\n",
        "print(len(pairs_encoded))\n",
        "# Shuffle the dataset first (important!)\n",
        "shuffle(pairs_encoded)\n",
        "\n",
        "# Define split sizes\n",
        "total = len(pairs_encoded)\n",
        "train_size = int(0.7 * total)\n",
        "val_size = int(0.15 * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "# Split the dataset\n",
        "train_data = pairs_encoded[:train_size]\n",
        "val_data = pairs_encoded[train_size:train_size + val_size]\n",
        "test_data = pairs_encoded[train_size + val_size:]"
      ],
      "metadata": {
        "id": "O6o7K3vadT9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775d40d3-8543-4a68-dde4-3fca836e88ea"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset and dataloader\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, pairs):\n",
        "\n",
        "        self.pairs = pairs\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        question = torch.LongTensor(self.pairs[i][0])\n",
        "        reply_input = torch.LongTensor(self.pairs[i][1])\n",
        "        reply = torch.LongTensor(self.pairs[i][2])\n",
        "        return question, reply_input, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "\n",
        "#train_loader = DataLoader(Dataset(pairs_encoded), batch_size=32, shuffle=True, pin_memory=True)\n",
        "train_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(Dataset(train_data), batch_size=1, shuffle=False, pin_memory=True)\n",
        "question, reply_input, reply = next(iter(train_loader))\n",
        "print(\"Question: \", question.size())\n",
        "print(\"Answer: \", reply_input.size())\n",
        "print(\"Answer: \", reply.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYN8aEqWdiaC",
        "outputId": "807e83c1-1dac-4a37-ad38-13cb39877d89"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=2, max_len=25):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
        "        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) ## every other column, starting with the 1st, has sin() values\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) ## every other column, starting with the 2nd, has cos() values\n",
        "\n",
        "        ## Now we \"register 'pe'.\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, word_embeddings):\n",
        "\n",
        "        return word_embeddings + self.pe[:word_embeddings.size(0), :]\n"
      ],
      "metadata": {
        "id": "hHr9QLj2eDa6"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=2,row_dim=0,col_dim=1):\n",
        "      super().__init__()\n",
        "      self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "      self.row_dim = row_dim\n",
        "      self.col_dim = col_dim\n",
        "\n",
        "\n",
        "    ## The only change from SelfAttention and attention is that\n",
        "    ## now we expect 3 sets of encodings to be passed in...\n",
        "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
        "        ## ...and we pass those sets of encodings to the various weight matrices.\n",
        "        q = self.W_q(encodings_for_q)\n",
        "        k = self.W_k(encodings_for_k)\n",
        "        v = self.W_v(encodings_for_v)\n",
        "        # Transpose keys: [batch_size, d_model, seq_len_k]\n",
        "        if q.dim() == 3:  # [batch_size, seq_len, d_model]\n",
        "          k_t = k.transpose(1, 2)         # [batch_size, d_model, seq_len]\n",
        "          sims = torch.bmm(q, k_t)        # [batch_size, seq_len_q, seq_len_k]\n",
        "        else:  # assume [seq_len, d_model] (no batch)\n",
        "          k_t = k.transpose(0, 1)         # [d_model, seq_len]\n",
        "          sims = torch.matmul(q, k_t)     # [seq_len_q, seq_len_k]\n",
        "\n",
        "        scaled_sims = sims / torch.tensor(k.size(-1)**0.5)\n",
        "\n",
        "\n",
        "        if mask is not None:\n",
        "            #print(\"mask.shape, scaled_sims.shape\",mask.shape, scaled_sims.shape )\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "CNBTcs7nfMxJ"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "\n",
        "        word_embeddings = self.we(token_ids)\n",
        "\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "\n",
        "        self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=None)\n",
        "\n",
        "\n",
        "        residual_connection_values = self.layernorm(position_encoded + self_attention_values)\n",
        "\n",
        "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
        "\n",
        "        return residual_connection_values, residual_connection_values\n"
      ],
      "metadata": {
        "id": "QiXmZbOgf7xn"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "        ## NOTE: In this simple example, we are just using a \"single layer\" decoder.\n",
        "        ##       If we wanted to have multiple layers of decoder, then we would\n",
        "        ##       take the output of one decoder module and use it as input to\n",
        "        ##       the next module.\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.cross_attention = Attention(d_model=d_model)\n",
        "        self.layernorm1 = nn.LayerNorm(d_model)\n",
        "        self.layernorm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids,encoder_k, encoder_v):\n",
        "        device = token_ids.device\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "        if token_ids.dim() == 2:\n",
        "          mask = torch.tril(torch.ones((token_ids.size(1), token_ids.size(1))))\n",
        "          mask = mask.unsqueeze(0).expand(token_ids.size(0), -1, -1)  # [batch_size, seq_len, seq_len]\n",
        "        elif token_ids.dim() == 1:\n",
        "          mask = torch.tril(torch.ones((token_ids.size(0), token_ids.size(0))))\n",
        "        #mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=1))))\n",
        "        mask = mask == 0\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        mask_self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=mask)\n",
        "\n",
        "        residual_connection_values = self.layernorm1(position_encoded + mask_self_attention_values)\n",
        "        x_cross_att = self.cross_attention(residual_connection_values, encoder_k, encoder_v, mask=None)\n",
        "        x = self.layernorm2(residual_connection_values + x_cross_att)\n",
        "        fc_layer_output = self.fc_layer(x)\n",
        "\n",
        "\n",
        "\n",
        "        return fc_layer_output\n"
      ],
      "metadata": {
        "id": "xIRWAdRHgDAf"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## First, create a model from DecoderOnlyTransformer()\n",
        "model = Encoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "\n",
        "\n",
        "## Now create the input for the transformer...\n",
        "question_test = pairs[20][0]\n",
        "print(question_test)\n",
        "mapped_values = [word_map[word] for word in question_test]\n",
        "encoder_input = torch.tensor(mapped_values)\n",
        "print(\"encoder_input\", encoder_input.shape)\n",
        "\n",
        "## Now get get predictions from the model\n",
        "encoder_k, encoder_v = model(encoder_input)\n",
        "answer_test = pairs[20][1]\n",
        "print(answer_test)\n",
        "mapped_values = [word_map['<start>']]+[word_map[word] for word in answer_test]\n",
        "decoder_input = torch.tensor(mapped_values)\n",
        "print(\"decoder_input\", decoder_input.shape)\n",
        "decoder = Decoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "output = decoder(decoder_input, encoder_k, encoder_v)\n",
        "\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "BppoaYtDgjl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc3ff3e-4717-4396-ad9c-6f9d550a5e6f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes']\n",
            "encoder_input torch.Size([14])\n",
            "['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']\n",
            "decoder_input torch.Size([14])\n",
            "tensor([[ 1.0339e+00,  8.8464e-02,  4.3018e-01,  ...,  3.5955e-01,\n",
            "         -1.3129e+00,  1.5639e+00],\n",
            "        [-8.5730e-02, -6.6056e-01,  1.2514e-03,  ...,  3.1146e-02,\n",
            "          1.3571e+00, -4.7436e-01],\n",
            "        [ 1.0339e+00,  8.8464e-02,  4.3018e-01,  ...,  3.5955e-01,\n",
            "         -1.3129e+00,  1.5639e+00],\n",
            "        ...,\n",
            "        [ 1.0339e+00,  8.8464e-02,  4.3018e-01,  ...,  3.5955e-01,\n",
            "         -1.3129e+00,  1.5639e+00],\n",
            "        [ 1.0339e+00,  8.8464e-02,  4.3018e-01,  ...,  3.5955e-01,\n",
            "         -1.3129e+00,  1.5639e+00],\n",
            "        [ 1.0339e+00,  8.8464e-02,  4.3018e-01,  ...,  3.5955e-01,\n",
            "         -1.3129e+00,  1.5639e+00]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "num_tokens = len(word_map)\n",
        "d_model = 2\n",
        "max_len = 25\n",
        "batch_size = 32\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "6KYuFoGRmJMO"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the transformer model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_tokens, d_model, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "        self.decoder = Decoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "        # Output projection layer\n",
        "        self.output_linear = nn.Linear(num_tokens, num_tokens)\n",
        "\n",
        "    def forward(self, src_tokens, tgt_tokens):\n",
        "        # Pass source tokens through encoder\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "        # Pass target tokens and encoder outputs through decoder\n",
        "        decoder_output = self.decoder(tgt_tokens, encoder_output, encoder_hidden)\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "    def generate(self, src_tokens, max_len=10, start_token=4): # 4 is\n",
        "        device = src_tokens.device\n",
        "\n",
        "        # Encode the source sequence\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "\n",
        "        # Initialize decoder input with start token\n",
        "        decoder_input = torch.tensor([word_map['hi']])\n",
        "\n",
        "\n",
        "        generated_sequence = [start_token]\n",
        "\n",
        "        # Generate tokens one by one\n",
        "        for _ in range(max_len):\n",
        "            # Get decoder output\n",
        "            decoder_output = self.decoder(decoder_input, encoder_output, encoder_hidden)\n",
        "\n",
        "            # Get the predicted token\n",
        "            _, topi = decoder_output[-1].topk(1)\n",
        "            predicted_token = topi.item()\n",
        "\n",
        "            # Add to the generated sequence\n",
        "            generated_sequence.append(predicted_token)\n",
        "\n",
        "            # Stop if we generated an  token\n",
        "            if predicted_token == word_map['hi']:\n",
        "                break\n",
        "\n",
        "            # Update decoder input\n",
        "            decoder_input = torch.cat([decoder_input, torch.tensor([predicted_token], device=device)], dim=0)\n",
        "\n",
        "        return generated_sequence\n"
      ],
      "metadata": {
        "id": "uRptHOJemrlG"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Transformer(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1jo2SK7bm3_g"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2zzTgKflXYM",
        "outputId": "bd6beb84-6931-4d7d-d8d9-be470092b75a"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (we): Embedding(18243, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18243, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (we): Embedding(18243, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (cross_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm1): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (layernorm2): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18243, bias=True)\n",
              "  )\n",
              "  (output_linear): Linear(in_features=18243, out_features=18243, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        print(f\"\\nüåü Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training loop\n",
        "        for i, (src, tgt_in, tgt_out) in enumerate(train_loader):\n",
        "            try:\n",
        "                optimizer.zero_grad()\n",
        "                src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "                #print(f\"üîÅ Training Iteration {i}\")\n",
        "\n",
        "                output = model(src, tgt_in)\n",
        "                output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                loss = criterion(output_flat, target_flat)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error at training iteration {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        training_loss.append(epoch_loss / len(train_loader))\n",
        "        print(f\"‚úÖ Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for j, (src, tgt_in, tgt_out) in enumerate(val_loader):\n",
        "                try:\n",
        "                    src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "                    output = model(src, tgt_in)\n",
        "                    output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                    target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                    loss = criterion(output_flat, target_flat)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error at validation iteration {j}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        validation_loss.append(avg_val_loss)\n",
        "        print(f\"üß™ Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        model.train()  # switch back to training mode\n",
        "    return training_loss, validation_loss\n"
      ],
      "metadata": {
        "id": "cs4Wx2IwpBlv"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "avg_train_loss, avg_val_loss=train()"
      ],
      "metadata": {
        "id": "IIhgMtZXqZ-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4a33d0-5ad3-4fa7-c96d-ba18cca097da"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üåü Epoch 1/2\n",
            "‚ùå Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "‚úÖ Epoch 1 Training Loss: 4.1675\n",
            "‚ùå Error at validation iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "üß™ Epoch 1 Validation Loss: 2.6774\n",
            "\n",
            "üåü Epoch 2/2\n",
            "‚ùå Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "‚úÖ Epoch 2 Training Loss: 2.5793\n",
            "‚ùå Error at validation iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "üß™ Epoch 2 Validation Loss: 2.5288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4ouVGB4BVc7E"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(avg_train_loss, avg_val_loss)"
      ],
      "metadata": {
        "id": "5f-PsP2oVkQv",
        "outputId": "7a18d350-d5e6-44ac-eb4a-55b2a9864832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_map['hi']"
      ],
      "metadata": {
        "id": "QF7MuPx5gTJi",
        "outputId": "db640730-27d9-4eca-ab65-8893e1c3998e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (src, tgt_in, tgt_out) in enumerate(test_loader):\n",
        "  src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "  model.generate(tgt_in, max_len=25, start_token=word_map[\"<start>\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "wr2SJYjltdjD",
        "outputId": "c368834d-b5f2-498e-f4c5-75bbef442346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-80202e81fd34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<start>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-138-a59f5bd8f0c6>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, src_tokens, max_len, start_token)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Get decoder output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Get the predicted token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-6910f43ed712>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, encoder_k, encoder_v)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mposition_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    }
  ]
}
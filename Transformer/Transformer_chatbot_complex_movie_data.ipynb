{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannisthamaiti/AIWeekend-Project/blob/main/Transformer/Transformer_chatbot_complex_movie_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBbUJEFwbZ4V",
        "outputId": "f213bdcc-b859-48d6-e6f7-a60f4a0e1a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "--2025-05-14 20:30:55--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.53\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip [following]\n",
            "--2025-05-14 20:30:55--  https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  12.8MB/s    in 0.7s    \n",
            "\n",
            "2025-05-14 20:30:56 (12.8 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch transformers\n",
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
        "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
        "!rm cornell_movie_dialogs_corpus.zip\n",
        "!mkdir datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "\n",
        "This tutorial trains a Transformer model to be a chatbot. This is an advanced example that assumes knowledge of text generation, attention and transformer.\n",
        "\n",
        "We will use the conversations in movies and TV shows provided by Cornell Movie-Dialogs Corpus, which contains more than 220 thousands conversational exchanges between more than 10k pairs of movie characters, as our dataset.\n",
        "\n",
        "movie_conversations.txt contains list of the conversation IDs and movie_lines.text contains the text of assoicated with each conversation ID. For further information regarding the dataset, please check the README file in the zip file."
      ],
      "metadata": {
        "id": "v5pnboqLbvJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import math\n"
      ],
      "metadata": {
        "id": "rrrHwFJOdAzi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax()\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset ## We'll store our data in DataLoaders\n",
        "from torch.optim import Adam\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "izzM6fe_oUnr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(string):\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punct = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char  # space is also a character\n",
        "    return no_punct.lower()"
      ],
      "metadata": {
        "id": "wG-lPDUJcQWu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "max_len = 25\n",
        "\n",
        "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
        "corpus_movie_lines = './datasets/movie_lines.txt'\n",
        "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
        "    conv = c.readlines()\n",
        "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
        "    lines = l.readlines()\n",
        "\n",
        "# extract text\n",
        "lines_dic = {}\n",
        "for line in lines:\n",
        "    objects = line.split(\" +++$+++ \")\n",
        "    lines_dic[objects[0]] = objects[-1]"
      ],
      "metadata": {
        "id": "aeOfqGIvbtiS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate question answer pairs\n",
        "pairs = []\n",
        "for con in conv:\n",
        "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        if i == len(ids) - 1:\n",
        "            break\n",
        "\n",
        "        first = remove_punc(lines_dic[ids[i]].strip())\n",
        "        second = remove_punc(lines_dic[ids[i+1]].strip())\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        pairs.append(qa_pairs)\n",
        "\n",
        "# sample\n",
        "print(pairs[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XagHo-TccGk",
        "outputId": "fc9afd8e-691d-4926-8793-4af8718499d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding"
      ],
      "metadata": {
        "id": "t_Mr4nfjc2vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word map\n",
        "min_word_freq = 5\n",
        "\n",
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "    word_freq.update(pair[0])\n",
        "    word_freq.update(pair[1])\n",
        "\n",
        "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "word_map['<unk>'] = len(word_map) + 1\n",
        "word_map['<start>'] = len(word_map) + 1\n",
        "word_map['<end>'] = len(word_map) + 1\n",
        "word_map['<pad>'] = 0\n",
        "\n",
        "print(\"Total words are: {}\".format(len(word_map)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DwFdaN3crWj",
        "outputId": "62ea39f2-9dbc-4f02-f806-9cfba7363f45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words are: 18243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "# encode sentences based on word map\n",
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply_input(words, word_map):\n",
        "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "\n",
        "pairs_encoded = []\n",
        "for pair in pairs:\n",
        "    qus = encode_question(pair[0], word_map)\n",
        "    ans_input = encode_reply_input(pair[1], word_map)\n",
        "    ans = encode_reply(pair[2], word_map)\n",
        "    if len(qus) == 25 and len(ans_input) == 25 and len(ans) == 25:\n",
        "      pairs_encoded.append([qus, ans_input,ans])\n",
        "print(len(pairs_encoded))\n",
        "# Shuffle the dataset first (important!)\n",
        "shuffle(pairs_encoded)\n",
        "\n",
        "# Define split sizes\n",
        "total = len(pairs_encoded)\n",
        "train_size = int(0.7 * total)\n",
        "val_size = int(0.15 * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "# Split the dataset\n",
        "train_data = pairs_encoded[:train_size]\n",
        "val_data = pairs_encoded[train_size:train_size + val_size]\n",
        "test_data = pairs_encoded[train_size + val_size:]"
      ],
      "metadata": {
        "id": "O6o7K3vadT9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0244ace7-77d2-4569-e96e-2781e3c56548"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset and dataloader\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, pairs):\n",
        "\n",
        "        self.pairs = pairs\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        question = torch.LongTensor(self.pairs[i][0])\n",
        "        reply_input = torch.LongTensor(self.pairs[i][1])\n",
        "        reply = torch.LongTensor(self.pairs[i][2])\n",
        "        return question, reply_input, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "\n",
        "#train_loader = DataLoader(Dataset(pairs_encoded), batch_size=32, shuffle=True, pin_memory=True)\n",
        "train_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(Dataset(train_data), batch_size=1, shuffle=False, pin_memory=True)\n",
        "question, reply_input, reply = next(iter(train_loader))\n",
        "print(\"Question: \", question.size())\n",
        "print(\"Answer: \", reply_input.size())\n",
        "print(\"Answer: \", reply.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYN8aEqWdiaC",
        "outputId": "11051b78-bd85-4bb1-b874-0f40616479b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=2, max_len=25):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
        "        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) ## every other column, starting with the 1st, has sin() values\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) ## every other column, starting with the 2nd, has cos() values\n",
        "\n",
        "        ## Now we \"register 'pe'.\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, word_embeddings):\n",
        "\n",
        "        return word_embeddings + self.pe[:word_embeddings.size(0), :]\n"
      ],
      "metadata": {
        "id": "hHr9QLj2eDa6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=2,row_dim=0,col_dim=1):\n",
        "      super().__init__()\n",
        "      self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "      self.row_dim = row_dim\n",
        "      self.col_dim = col_dim\n",
        "\n",
        "\n",
        "    ## The only change from SelfAttention and attention is that\n",
        "    ## now we expect 3 sets of encodings to be passed in...\n",
        "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
        "        ## ...and we pass those sets of encodings to the various weight matrices.\n",
        "        q = self.W_q(encodings_for_q)\n",
        "        k = self.W_k(encodings_for_k)\n",
        "        v = self.W_v(encodings_for_v)\n",
        "        # Transpose keys: [batch_size, d_model, seq_len_k]\n",
        "        if q.dim() == 3:  # [batch_size, seq_len, d_model]\n",
        "          k_t = k.transpose(1, 2)         # [batch_size, d_model, seq_len]\n",
        "          sims = torch.bmm(q, k_t)        # [batch_size, seq_len_q, seq_len_k]\n",
        "        else:  # assume [seq_len, d_model] (no batch)\n",
        "          k_t = k.transpose(0, 1)         # [d_model, seq_len]\n",
        "          sims = torch.matmul(q, k_t)     # [seq_len_q, seq_len_k]\n",
        "\n",
        "        scaled_sims = sims / torch.tensor(k.size(-1)**0.5)\n",
        "\n",
        "\n",
        "        if mask is not None:\n",
        "            #print(\"mask.shape, scaled_sims.shape\",mask.shape, scaled_sims.shape )\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "CNBTcs7nfMxJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "\n",
        "        word_embeddings = self.we(token_ids)\n",
        "\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "\n",
        "        self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=None)\n",
        "\n",
        "\n",
        "        residual_connection_values = self.layernorm(position_encoded + self_attention_values)\n",
        "\n",
        "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
        "\n",
        "        return residual_connection_values, residual_connection_values\n"
      ],
      "metadata": {
        "id": "QiXmZbOgf7xn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "        ## NOTE: In this simple example, we are just using a \"single layer\" decoder.\n",
        "        ##       If we wanted to have multiple layers of decoder, then we would\n",
        "        ##       take the output of one decoder module and use it as input to\n",
        "        ##       the next module.\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.cross_attention = Attention(d_model=d_model)\n",
        "        self.layernorm1 = nn.LayerNorm(d_model)\n",
        "        self.layernorm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids,encoder_k, encoder_v):\n",
        "        device = token_ids.device\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "        if token_ids.dim() == 2:\n",
        "          mask = torch.tril(torch.ones((token_ids.size(1), token_ids.size(1))))\n",
        "          mask = mask.unsqueeze(0).expand(token_ids.size(0), -1, -1)  # [batch_size, seq_len, seq_len]\n",
        "        elif token_ids.dim() == 1:\n",
        "          mask = torch.tril(torch.ones((token_ids.size(0), token_ids.size(0))))\n",
        "        #mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=1))))\n",
        "        mask = mask == 0\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        mask_self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=mask)\n",
        "\n",
        "        residual_connection_values = self.layernorm1(position_encoded + mask_self_attention_values)\n",
        "        x_cross_att = self.cross_attention(residual_connection_values, encoder_k, encoder_v, mask=None)\n",
        "        x = self.layernorm2(residual_connection_values + x_cross_att)\n",
        "        fc_layer_output = self.fc_layer(x)\n",
        "\n",
        "\n",
        "\n",
        "        return fc_layer_output\n"
      ],
      "metadata": {
        "id": "xIRWAdRHgDAf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## First, create a model from DecoderOnlyTransformer()\n",
        "model = Encoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "\n",
        "\n",
        "## Now create the input for the transformer...\n",
        "question_test = pairs[20][0]\n",
        "print(question_test)\n",
        "mapped_values = [word_map[word] for word in question_test]\n",
        "encoder_input = torch.tensor(mapped_values)\n",
        "print(\"encoder_input\", encoder_input.shape)\n",
        "\n",
        "## Now get get predictions from the model\n",
        "encoder_k, encoder_v = model(encoder_input)\n",
        "answer_test = pairs[20][1]\n",
        "print(answer_test)\n",
        "mapped_values = [word_map['<start>']]+[word_map[word] for word in answer_test]\n",
        "decoder_input = torch.tensor(mapped_values)\n",
        "print(\"decoder_input\", decoder_input.shape)\n",
        "decoder = Decoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "output = decoder(decoder_input, encoder_k, encoder_v)\n",
        "\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "BppoaYtDgjl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15134a8d-b8f2-4d25-c055-207315098a60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes']\n",
            "encoder_input torch.Size([14])\n",
            "['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']\n",
            "decoder_input torch.Size([14])\n",
            "tensor([[ 0.4360,  0.0695, -0.3052,  ..., -0.0068,  0.1273,  1.2307],\n",
            "        [ 0.5314, -0.4737, -0.7034,  ..., -0.2035, -0.7354, -0.4376],\n",
            "        [ 0.5314, -0.4737, -0.7034,  ..., -0.2035, -0.7354, -0.4376],\n",
            "        ...,\n",
            "        [ 0.4360,  0.0695, -0.3052,  ..., -0.0068,  0.1273,  1.2307],\n",
            "        [ 0.4360,  0.0695, -0.3052,  ..., -0.0068,  0.1273,  1.2307],\n",
            "        [ 0.4360,  0.0695, -0.3052,  ..., -0.0068,  0.1273,  1.2307]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "num_tokens = len(word_map)\n",
        "d_model = 2\n",
        "max_len = 25\n",
        "batch_size = 32\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "6KYuFoGRmJMO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the transformer model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_tokens, d_model, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "        self.decoder = Decoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "        # Output projection layer\n",
        "        self.output_linear = nn.Linear(num_tokens, num_tokens)\n",
        "\n",
        "    def forward(self, src_tokens, tgt_tokens):\n",
        "        # Pass source tokens through encoder\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "        # Pass target tokens and encoder outputs through decoder\n",
        "        decoder_output = self.decoder(tgt_tokens, encoder_output, encoder_hidden)\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "    def generate(self, src_tokens, max_len=10, start_token=4): # 4 is\n",
        "        device = src_tokens.device\n",
        "\n",
        "        # Encode the source sequence\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "\n",
        "        # Initialize decoder input with start token\n",
        "        decoder_input = torch.tensor([word_map[\"\"]])\n",
        "\n",
        "\n",
        "        generated_sequence = [start_token]\n",
        "\n",
        "        # Generate tokens one by one\n",
        "        for _ in range(max_len):\n",
        "            # Get decoder output\n",
        "            decoder_output = self.decoder(decoder_input, encoder_output, encoder_hidden)\n",
        "\n",
        "            # Get the predicted token\n",
        "            _, topi = decoder_output[-1].topk(1)\n",
        "            predicted_token = topi.item()\n",
        "\n",
        "            # Add to the generated sequence\n",
        "            generated_sequence.append(predicted_token)\n",
        "\n",
        "            # Stop if we generated an  token\n",
        "            if predicted_token == word_map[\"\"]:\n",
        "                break\n",
        "\n",
        "            # Update decoder input\n",
        "            decoder_input = torch.cat([decoder_input, torch.tensor([predicted_token], device=device)], dim=0)\n",
        "\n",
        "        return generated_sequence\n"
      ],
      "metadata": {
        "id": "uRptHOJemrlG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Transformer(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1jo2SK7bm3_g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2zzTgKflXYM",
        "outputId": "bf4596c3-fc67-44ee-e22a-b53da0159b2f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (we): Embedding(18243, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18243, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (we): Embedding(18243, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (cross_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm1): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (layernorm2): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18243, bias=True)\n",
              "  )\n",
              "  (output_linear): Linear(in_features=18243, out_features=18243, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        print(f\"\\n🌟 Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training loop\n",
        "        for i, (src, tgt_in, tgt_out) in enumerate(train_loader):\n",
        "            try:\n",
        "                optimizer.zero_grad()\n",
        "                src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "                #print(f\"🔁 Training Iteration {i}\")\n",
        "\n",
        "                output = model(src, tgt_in)\n",
        "                output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                loss = criterion(output_flat, target_flat)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error at training iteration {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        training_loss.append(epoch_loss / len(train_loader))\n",
        "        print(f\"✅ Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for j, (src, tgt_in, tgt_out) in enumerate(val_loader):\n",
        "                try:\n",
        "                    src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "                    output = model(src, tgt_in)\n",
        "                    output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                    target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                    loss = criterion(output_flat, target_flat)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error at validation iteration {j}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        validation_loss.append(avg_val_loss)\n",
        "        print(f\"🧪 Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        model.train()  # switch back to training mode\n",
        "    return training_loss, validation_loss\n"
      ],
      "metadata": {
        "id": "cs4Wx2IwpBlv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "avg_train_loss, avg_val_loss=train()"
      ],
      "metadata": {
        "id": "IIhgMtZXqZ-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7e1d35-1fd2-4d8b-8b72-b339ab0367ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🌟 Epoch 1/2\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 1 Training Loss: 3.7242\n",
            "❌ Error at validation iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "🧪 Epoch 1 Validation Loss: 2.7497\n",
            "\n",
            "🌟 Epoch 2/2\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 2 Training Loss: 2.7503\n",
            "❌ Error at validation iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "🧪 Epoch 2 Validation Loss: 2.7477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4ouVGB4BVc7E"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(avg_train_loss, avg_val_loss)"
      ],
      "metadata": {
        "id": "5f-PsP2oVkQv",
        "outputId": "fdfd7551-f8f3-4ec5-cf89-4a9067ca4c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_map[\"<start>\"]"
      ],
      "metadata": {
        "id": "QF7MuPx5gTJi",
        "outputId": "91f05256-a39e-4c3f-f5e4-c581cd5ffaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18241"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (src, tgt_in, tgt_out) in enumerate(test_loader):\n",
        "  src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "  model.generate(tgt_in, max_len=25, start_token=word_map[\"<start>\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "wr2SJYjltdjD",
        "outputId": "b8caf137-0a26-413c-e847-c6478d9fe535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'token_to_id' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-80202e81fd34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<start>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-5cb50d46e2ee>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, src_tokens, max_len, start_token)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Initialize decoder input with start token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'token_to_id' is not defined"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannisthamaiti/AIWeekend-Project/blob/main/Transformer/Transformer_chatbot_complex_movie_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBbUJEFwbZ4V",
        "outputId": "5c267978-c5eb-4d28-b9a3-a2fe5cfe3d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2025-05-15 10:58:10--  https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.53\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  4.19MB/s    in 2.3s    \n",
            "\n",
            "2025-05-15 10:58:13 (4.19 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n",
            "replace cornell movie-dialogs corpus/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/cornell movie-dialogs corpus/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/chameleons.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/movie_characters_metadata.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/movie_titles_metadata.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/raw_script_urls.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace cornell movie-dialogs corpus/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace __MACOSX/cornell movie-dialogs corpus/._README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "mkdir: cannot create directory ‘datasets’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch transformers\n",
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
        "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
        "!rm cornell_movie_dialogs_corpus.zip\n",
        "!mkdir datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "\n",
        "This tutorial trains a Transformer model to be a chatbot. This is an advanced example that assumes knowledge of text generation, attention and transformer.\n",
        "\n",
        "We will use the conversations in movies and TV shows provided by Cornell Movie-Dialogs Corpus, which contains more than 220 thousands conversational exchanges between more than 10k pairs of movie characters, as our dataset.\n",
        "\n",
        "movie_conversations.txt contains list of the conversation IDs and movie_lines.text contains the text of assoicated with each conversation ID. For further information regarding the dataset, please check the README file in the zip file."
      ],
      "metadata": {
        "id": "v5pnboqLbvJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import math\n"
      ],
      "metadata": {
        "id": "rrrHwFJOdAzi"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax()\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset ## We'll store our data in DataLoaders\n",
        "from torch.optim import Adam\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "izzM6fe_oUnr"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(string):\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punct = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char  # space is also a character\n",
        "    return no_punct.lower()"
      ],
      "metadata": {
        "id": "wG-lPDUJcQWu"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "max_len = 25\n",
        "\n",
        "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
        "corpus_movie_lines = './datasets/movie_lines.txt'\n",
        "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
        "    conv = c.readlines()\n",
        "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
        "    lines = l.readlines()\n",
        "\n",
        "# extract text\n",
        "lines_dic = {}\n",
        "for line in lines:\n",
        "    objects = line.split(\" +++$+++ \")\n",
        "    lines_dic[objects[0]] = objects[-1]"
      ],
      "metadata": {
        "id": "aeOfqGIvbtiS"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate question answer pairs\n",
        "pairs = []\n",
        "for con in conv:\n",
        "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        if i == len(ids) - 1:\n",
        "            break\n",
        "\n",
        "        first = remove_punc(lines_dic[ids[i]].strip())\n",
        "        second = remove_punc(lines_dic[ids[i+1]].strip())\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        pairs.append(qa_pairs)\n",
        "\n",
        "# sample\n",
        "print(pairs[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XagHo-TccGk",
        "outputId": "40a35f69-f4fb-4124-eeb5-6c8b1b7bccef"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding"
      ],
      "metadata": {
        "id": "t_Mr4nfjc2vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word map\n",
        "min_word_freq = 5\n",
        "\n",
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "    word_freq.update(pair[0])\n",
        "    word_freq.update(pair[1])\n",
        "\n",
        "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "word_map['<unk>'] = len(word_map) + 1\n",
        "word_map['<start>'] = len(word_map) + 1\n",
        "word_map['<end>'] = len(word_map) + 1\n",
        "word_map['<pad>'] = 0\n",
        "\n",
        "print(\"Total words are: {}\".format(len(word_map)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DwFdaN3crWj",
        "outputId": "544c3273-c3dc-440e-cde5-f8b5ef1bb7e4"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words are: 18243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "# encode sentences based on word map\n",
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply_input(words, word_map):\n",
        "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "\n",
        "pairs_encoded = []\n",
        "for pair in pairs:\n",
        "    qus = encode_question(pair[0], word_map)\n",
        "    ans_input = encode_reply_input(pair[1], word_map)\n",
        "    ans = encode_reply(pair[2], word_map)\n",
        "    if len(qus) == 25 and len(ans_input) == 25 and len(ans) == 25:\n",
        "      pairs_encoded.append([qus, ans_input,ans])\n",
        "print(len(pairs_encoded))\n",
        "# Shuffle the dataset first (important!)\n",
        "shuffle(pairs_encoded)\n",
        "\n",
        "# Define split sizes\n",
        "total = len(pairs_encoded)\n",
        "train_size = int(0.7 * total)\n",
        "val_size = int(0.15 * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "# Split the dataset\n",
        "train_data = pairs_encoded[:train_size]\n",
        "val_data = pairs_encoded[train_size:train_size + val_size]\n",
        "test_data = pairs_encoded[train_size + val_size:]"
      ],
      "metadata": {
        "id": "O6o7K3vadT9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4334dd83-08e0-437c-d463-8bf07b4594ec"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset and dataloader\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, pairs):\n",
        "\n",
        "        self.pairs = pairs\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        question = torch.LongTensor(self.pairs[i][0])\n",
        "        reply_input = torch.LongTensor(self.pairs[i][1])\n",
        "        reply = torch.LongTensor(self.pairs[i][2])\n",
        "        return question, reply_input, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "\n",
        "#train_loader = DataLoader(Dataset(pairs_encoded), batch_size=32, shuffle=True, pin_memory=True)\n",
        "train_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(Dataset(train_data), batch_size=1, shuffle=False, pin_memory=True)\n",
        "question, reply_input, reply = next(iter(train_loader))\n",
        "print(\"Question: \", question.size())\n",
        "print(\"Answer: \", reply_input.size())\n",
        "print(\"Answer: \", reply.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYN8aEqWdiaC",
        "outputId": "def9b529-a3e9-4a3e-8f44-3f59bd42cf30"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=2, max_len=25):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
        "        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) ## every other column, starting with the 1st, has sin() values\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) ## every other column, starting with the 2nd, has cos() values\n",
        "\n",
        "        ## Now we \"register 'pe'.\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, word_embeddings):\n",
        "\n",
        "        return word_embeddings + self.pe[:word_embeddings.size(0), :]\n"
      ],
      "metadata": {
        "id": "hHr9QLj2eDa6"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=2,row_dim=0,col_dim=1):\n",
        "      super().__init__()\n",
        "      self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "      self.row_dim = row_dim\n",
        "      self.col_dim = col_dim\n",
        "\n",
        "\n",
        "    ## The only change from SelfAttention and attention is that\n",
        "    ## now we expect 3 sets of encodings to be passed in...\n",
        "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
        "        ## ...and we pass those sets of encodings to the various weight matrices.\n",
        "        q = self.W_q(encodings_for_q)\n",
        "        k = self.W_k(encodings_for_k)\n",
        "        v = self.W_v(encodings_for_v)\n",
        "        # Transpose keys: [batch_size, d_model, seq_len_k]\n",
        "        if q.dim() == 3:  # [batch_size, seq_len, d_model]\n",
        "          k_t = k.transpose(1, 2)         # [batch_size, d_model, seq_len]\n",
        "          sims = torch.bmm(q, k_t)        # [batch_size, seq_len_q, seq_len_k]\n",
        "        else:  # assume [seq_len, d_model] (no batch)\n",
        "          k_t = k.transpose(0, 1)         # [d_model, seq_len]\n",
        "          sims = torch.matmul(q, k_t)     # [seq_len_q, seq_len_k]\n",
        "\n",
        "        scaled_sims = sims / torch.tensor(k.size(-1)**0.5)\n",
        "\n",
        "\n",
        "        if mask is not None:\n",
        "            #print(\"mask.shape, scaled_sims.shape\",mask.shape, scaled_sims.shape )\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "CNBTcs7nfMxJ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "\n",
        "        token_ids = token_ids.to(self.we.weight.device)\n",
        "\n",
        "        word_embeddings = self.we(token_ids)\n",
        "\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "\n",
        "        self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=None)\n",
        "\n",
        "\n",
        "        residual_connection_values = self.layernorm(position_encoded + self_attention_values)\n",
        "\n",
        "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
        "\n",
        "        return residual_connection_values, residual_connection_values\n"
      ],
      "metadata": {
        "id": "QiXmZbOgf7xn"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "        super().__init__()\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
        "        self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.cross_attention = Attention(d_model=d_model)\n",
        "        self.layernorm1 = nn.LayerNorm(d_model)\n",
        "        self.layernorm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "    def forward(self, token_ids, encoder_k, encoder_v):\n",
        "        device = self.we.weight.device  # ensure all tensors follow this device\n",
        "\n",
        "        token_ids = token_ids.to(device)\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "\n",
        "        # Create causal mask\n",
        "        seq_len = token_ids.size(1) if token_ids.dim() == 2 else token_ids.size(0)\n",
        "        batch_size = token_ids.size(0) if token_ids.dim() == 2 else 1\n",
        "        mask = torch.tril(torch.ones((seq_len, seq_len), device=device)).unsqueeze(0)\n",
        "        mask = mask.expand(batch_size, -1, -1)  # [batch_size, seq_len, seq_len]\n",
        "        mask = mask == 0  # convert to True/False for masked_fill\n",
        "\n",
        "        # Self-attention with mask\n",
        "        mask_self_attention_values = self.self_attention(\n",
        "            position_encoded, position_encoded, position_encoded, mask=mask\n",
        "        )\n",
        "\n",
        "        # Residual connection + layer norm\n",
        "        residual_connection_values = self.layernorm1(position_encoded + mask_self_attention_values)\n",
        "\n",
        "        # Cross-attention (no mask)\n",
        "        x_cross_att = self.cross_attention(residual_connection_values, encoder_k, encoder_v, mask=None)\n",
        "        x = self.layernorm2(residual_connection_values + x_cross_att)\n",
        "\n",
        "        fc_layer_output = self.fc_layer(x)\n",
        "        return fc_layer_output\n"
      ],
      "metadata": {
        "id": "xIRWAdRHgDAf"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## First, create a model from DecoderOnlyTransformer()\n",
        "model = Encoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "\n",
        "\n",
        "## Now create the input for the transformer...\n",
        "question_test = pairs[20][0]\n",
        "print(question_test)\n",
        "mapped_values = [word_map[word] for word in question_test]\n",
        "encoder_input = torch.tensor(mapped_values)\n",
        "print(\"encoder_input\", encoder_input.shape)\n",
        "\n",
        "## Now get get predictions from the model\n",
        "encoder_k, encoder_v = model(encoder_input)\n",
        "answer_test = pairs[20][1]\n",
        "print(answer_test)\n",
        "mapped_values = [word_map['<start>']]+[word_map[word] for word in answer_test]\n",
        "decoder_input = torch.tensor(mapped_values)\n",
        "print(\"decoder_input\", decoder_input.shape)\n",
        "decoder = Decoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "output = decoder(decoder_input, encoder_k, encoder_v)\n",
        "\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "BppoaYtDgjl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d24092-ef7f-48a6-c8e5-d07fb8377bce"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes']\n",
            "encoder_input torch.Size([14])\n",
            "['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']\n",
            "decoder_input torch.Size([14])\n",
            "tensor([[-0.2263,  0.4737, -0.6455,  ..., -0.3704,  0.0500, -0.7724],\n",
            "        [-0.0457, -0.6998,  1.2509,  ...,  1.3396, -0.6517, -0.4627],\n",
            "        [-0.2263,  0.4737, -0.6455,  ..., -0.3704,  0.0500, -0.7724],\n",
            "        ...,\n",
            "        [-0.2263,  0.4737, -0.6455,  ..., -0.3704,  0.0500, -0.7724],\n",
            "        [-0.2263,  0.4737, -0.6455,  ..., -0.3704,  0.0500, -0.7724],\n",
            "        [-0.0457, -0.6998,  1.2509,  ...,  1.3396, -0.6517, -0.4627]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "num_tokens = len(word_map)\n",
        "d_model = 2\n",
        "max_len = 25\n",
        "batch_size = 32\n",
        "num_epochs = 2\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "6KYuFoGRmJMO"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the transformer model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_tokens, d_model, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "        self.decoder = Decoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "        # Output projection layer\n",
        "        self.output_linear = nn.Linear(num_tokens, num_tokens)\n",
        "\n",
        "    def forward(self, src_tokens, tgt_tokens):\n",
        "        # Pass source tokens through encoder\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "        # Pass target tokens and encoder outputs through decoder\n",
        "        decoder_output = self.decoder(tgt_tokens, encoder_output, encoder_hidden)\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "    def generate(self, src_tokens, max_len=10, start_token=4): # 4 is\n",
        "        device = src_tokens.device\n",
        "\n",
        "\n",
        "        # Encode the source sequence\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "\n",
        "        # Initialize decoder input with start token\n",
        "        decoder_input = torch.tensor([word_map['hi']])\n",
        "\n",
        "\n",
        "        generated_sequence = [start_token]\n",
        "\n",
        "        # Generate tokens one by one\n",
        "        for _ in range(max_len):\n",
        "            # Get decoder output\n",
        "            decoder_output = self.decoder(decoder_input, encoder_output, encoder_hidden)\n",
        "\n",
        "            # Get the predicted token\n",
        "            _, topi = decoder_output[-1].topk(1)\n",
        "            predicted_token = topi.item()\n",
        "\n",
        "            # Add to the generated sequence\n",
        "            generated_sequence.append(predicted_token)\n",
        "\n",
        "            # Stop if we generated an  token\n",
        "            if predicted_token == word_map['hi']:\n",
        "                break\n",
        "\n",
        "            # Update decoder input\n",
        "            decoder_input = torch.cat([decoder_input, torch.tensor([predicted_token], device=device)], dim=0)\n",
        "\n",
        "        return generated_sequence\n"
      ],
      "metadata": {
        "id": "uRptHOJemrlG"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Transformer(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1jo2SK7bm3_g"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2zzTgKflXYM",
        "outputId": "ae3eef47-b756-4a98-962a-c74fa367d947"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (we): Embedding(18243, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18243, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (we): Embedding(18243, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (cross_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm1): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (layernorm2): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18243, bias=True)\n",
              "  )\n",
              "  (output_linear): Linear(in_features=18243, out_features=18243, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        print(f\"\\n🌟 Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training loop\n",
        "        for i, (src, tgt_in, tgt_out) in enumerate(train_loader):\n",
        "            try:\n",
        "                optimizer.zero_grad()\n",
        "                src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "                #print(f\"🔁 Training Iteration {i}\")\n",
        "\n",
        "                output = model(src, tgt_in)\n",
        "                output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                loss = criterion(output_flat, target_flat)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error at training iteration {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        training_loss.append(epoch_loss / len(train_loader))\n",
        "        print(f\"✅ Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for j, (src, tgt_in, tgt_out) in enumerate(val_loader):\n",
        "                try:\n",
        "                    src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "                    output = model(src, tgt_in)\n",
        "                    output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                    target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                    loss = criterion(output_flat, target_flat)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error at validation iteration {j}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        validation_loss.append(avg_val_loss)\n",
        "        print(f\"🧪 Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        model.train()  # switch back to training mode\n",
        "    return training_loss, validation_loss\n"
      ],
      "metadata": {
        "id": "cs4Wx2IwpBlv"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "avg_train_loss, avg_val_loss=train()"
      ],
      "metadata": {
        "id": "IIhgMtZXqZ-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb0efc5-0e18-441a-8f5b-534a4b0dcc38"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🌟 Epoch 1/2\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 1 Training Loss: 3.6073\n",
            "❌ Error at validation iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "🧪 Epoch 1 Validation Loss: 2.7452\n",
            "\n",
            "🌟 Epoch 2/2\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 2 Training Loss: 2.7475\n",
            "❌ Error at validation iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "🧪 Epoch 2 Validation Loss: 2.7444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4ouVGB4BVc7E"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(avg_train_loss, avg_val_loss)"
      ],
      "metadata": {
        "id": "5f-PsP2oVkQv",
        "outputId": "486a12ee-c460-46be-f4da-bc389b0922d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_map['hi']"
      ],
      "metadata": {
        "id": "QF7MuPx5gTJi",
        "outputId": "8a3ac1ab-e0e0-4b9d-84a8-f27d867d74eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (src, tgt_in, tgt_out) in enumerate(test_loader):\n",
        "  src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "  model.generate(tgt_in, max_len=25, start_token=word_map[\"<start>\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "wr2SJYjltdjD",
        "outputId": "074e5ab1-515f-41bd-c284-2d9c6d83223d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected self and mask to be on the same device, but got mask on cpu and self on cuda:0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-80202e81fd34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<start>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-ad29b98d46f3>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, src_tokens, max_len, start_token)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Get decoder output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Get the predicted token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-268d361d0667>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, encoder_k, encoder_v)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         mask_self_attention_values = self.self_attention(position_encoded,\n\u001b[0m\u001b[1;32m     47\u001b[0m                                                     \u001b[0mposition_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                                                     \u001b[0mposition_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-123-4e6be19ac011>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encodings_for_q, encodings_for_k, encodings_for_v, mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#print(\"mask.shape, scaled_sims.shape\",mask.shape, scaled_sims.shape )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mscaled_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_sims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mattention_percents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_sims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected self and mask to be on the same device, but got mask on cpu and self on cuda:0"
          ]
        }
      ]
    }
  ]
}
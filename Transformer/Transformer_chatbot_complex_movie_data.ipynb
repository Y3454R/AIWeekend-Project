{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannisthamaiti/AIWeekend-Project/blob/main/Transformer/Transformer_chatbot_complex_movie_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBbUJEFwbZ4V",
        "outputId": "963b659e-040a-4bcc-aa4f-fb42ca4d7c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "--2025-05-15 15:07:22--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.53\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip [following]\n",
            "--2025-05-15 15:07:23--  https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  13.7MB/s    in 0.7s    \n",
            "\n",
            "2025-05-15 15:07:24 (13.7 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets torch transformers\n",
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
        "!unzip -qq cornell_movie_dialogs_corpus.zip\n",
        "!rm cornell_movie_dialogs_corpus.zip\n",
        "!mkdir datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_conversations.txt ./datasets\n",
        "!mv cornell\\ movie-dialogs\\ corpus/movie_lines.txt ./datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "\n",
        "This tutorial trains a Transformer model to be a chatbot. This is an advanced example that assumes knowledge of text generation, attention and transformer.\n",
        "\n",
        "We will use the conversations in movies and TV shows provided by Cornell Movie-Dialogs Corpus, which contains more than 220 thousands conversational exchanges between more than 10k pairs of movie characters, as our dataset.\n",
        "\n",
        "movie_conversations.txt contains list of the conversation IDs and movie_lines.text contains the text of assoicated with each conversation ID. For further information regarding the dataset, please check the README file in the zip file."
      ],
      "metadata": {
        "id": "v5pnboqLbvJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import math\n"
      ],
      "metadata": {
        "id": "rrrHwFJOdAzi"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax()\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset ## We'll store our data in DataLoaders\n",
        "from torch.optim import Adam\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "izzM6fe_oUnr"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(string):\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punct = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char  # space is also a character\n",
        "    return no_punct.lower()"
      ],
      "metadata": {
        "id": "wG-lPDUJcQWu"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "max_len = 25\n",
        "\n",
        "corpus_movie_conv = './datasets/movie_conversations.txt'\n",
        "corpus_movie_lines = './datasets/movie_lines.txt'\n",
        "with open(corpus_movie_conv, 'r', encoding='iso-8859-1') as c:\n",
        "    conv = c.readlines()\n",
        "with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n",
        "    lines = l.readlines()\n",
        "\n",
        "# extract text\n",
        "lines_dic = {}\n",
        "for line in lines:\n",
        "    objects = line.split(\" +++$+++ \")\n",
        "    lines_dic[objects[0]] = objects[-1]"
      ],
      "metadata": {
        "id": "aeOfqGIvbtiS"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate question answer pairs\n",
        "pairs = []\n",
        "for con in conv:\n",
        "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
        "    for i in range(len(ids)):\n",
        "        qa_pairs = []\n",
        "\n",
        "        if i == len(ids) - 1:\n",
        "            break\n",
        "\n",
        "        first = remove_punc(lines_dic[ids[i]].strip())\n",
        "        second = remove_punc(lines_dic[ids[i+1]].strip())\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "        pairs.append(qa_pairs)\n",
        "\n",
        "# sample\n",
        "print(pairs[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XagHo-TccGk",
        "outputId": "f51f40b0-a7e0-43a0-cb4f-f428bb999094"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him'], ['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding"
      ],
      "metadata": {
        "id": "t_Mr4nfjc2vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word map\n",
        "min_word_freq = 5\n",
        "\n",
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "    word_freq.update(pair[0])\n",
        "    word_freq.update(pair[1])\n",
        "\n",
        "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
        "word_map['<unk>'] = len(word_map) + 1\n",
        "word_map['<start>'] = len(word_map) + 1\n",
        "word_map['<end>'] = len(word_map) + 1\n",
        "word_map[''] = len(word_map) + 1\n",
        "word_map['<pad>'] = 0\n",
        "\n",
        "print(\"Total words are: {}\".format(len(word_map)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DwFdaN3crWj",
        "outputId": "18d0fc9e-5494-4b19-b281-ffb9600c60a6"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words are: 18244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "# encode sentences based on word map\n",
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply_input(words, word_map):\n",
        "    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "def encode_reply(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']]\n",
        "    enc_c += [word_map['<pad>']] * (max_len - len(enc_c))\n",
        "    return enc_c\n",
        "\n",
        "\n",
        "pairs_encoded = []\n",
        "for pair in pairs:\n",
        "    qus = encode_question(pair[0], word_map)\n",
        "    ans_input = encode_reply_input(pair[1], word_map)\n",
        "    ans = encode_reply(pair[2], word_map)\n",
        "    if len(qus) == 25 and len(ans_input) == 25 and len(ans) == 25:\n",
        "      pairs_encoded.append([qus, ans_input,ans])\n",
        "print(len(pairs_encoded))\n",
        "# Shuffle the dataset first (important!)\n",
        "shuffle(pairs_encoded)\n",
        "\n",
        "# Define split sizes\n",
        "total = len(pairs_encoded)\n",
        "train_size = int(0.7 * total)\n",
        "val_size = int(0.2998 * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "# Split the dataset\n",
        "train_data = pairs_encoded[:train_size]\n",
        "val_data = pairs_encoded[train_size:train_size + val_size]\n",
        "test_data = pairs_encoded[train_size + val_size:]"
      ],
      "metadata": {
        "id": "O6o7K3vadT9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684cc376-c01e-471f-dfa4-c98bd27abbe7"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset and dataloader\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, pairs):\n",
        "\n",
        "        self.pairs = pairs\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        question = torch.LongTensor(self.pairs[i][0])\n",
        "        reply_input = torch.LongTensor(self.pairs[i][1])\n",
        "        reply = torch.LongTensor(self.pairs[i][2])\n",
        "        return question, reply_input, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "\n",
        "#train_loader = DataLoader(Dataset(pairs_encoded), batch_size=32, shuffle=True, pin_memory=True)\n",
        "train_loader = DataLoader(Dataset(train_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(Dataset(val_data), batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(Dataset(test_data), batch_size=1, shuffle=False, pin_memory=True)\n",
        "question, reply_input, reply = next(iter(train_loader))\n",
        "print(\"Question: \", question.size())\n",
        "print(\"Answer: \", reply_input.size())\n",
        "print(\"Answer: \", reply.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYN8aEqWdiaC",
        "outputId": "3a4a7817-d10b-43d1-ab22-0e2db0a0177e"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n",
            "Answer:  torch.Size([32, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=2, max_len=25):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
        "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
        "        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term) ## every other column, starting with the 1st, has sin() values\n",
        "        pe[:, 1::2] = torch.cos(position * div_term) ## every other column, starting with the 2nd, has cos() values\n",
        "\n",
        "        ## Now we \"register 'pe'.\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, word_embeddings):\n",
        "\n",
        "        return word_embeddings + self.pe[:word_embeddings.size(0), :]\n"
      ],
      "metadata": {
        "id": "hHr9QLj2eDa6"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model=2,row_dim=0,col_dim=1):\n",
        "      super().__init__()\n",
        "      self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "      self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "      self.row_dim = row_dim\n",
        "      self.col_dim = col_dim\n",
        "\n",
        "\n",
        "    ## The only change from SelfAttention and attention is that\n",
        "    ## now we expect 3 sets of encodings to be passed in...\n",
        "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
        "        ## ...and we pass those sets of encodings to the various weight matrices.\n",
        "        q = self.W_q(encodings_for_q)\n",
        "        k = self.W_k(encodings_for_k)\n",
        "        v = self.W_v(encodings_for_v)\n",
        "        # Transpose keys: [batch_size, d_model, seq_len_k]\n",
        "        if q.dim() == 3:  # [batch_size, seq_len, d_model]\n",
        "          k_t = k.transpose(1, 2)         # [batch_size, d_model, seq_len]\n",
        "          sims = torch.bmm(q, k_t)        # [batch_size, seq_len_q, seq_len_k]\n",
        "        else:  # assume [seq_len, d_model] (no batch)\n",
        "          k_t = k.transpose(0, 1)         # [d_model, seq_len]\n",
        "          sims = torch.matmul(q, k_t)     # [seq_len_q, seq_len_k]\n",
        "\n",
        "        scaled_sims = sims / torch.tensor(k.size(-1)**0.5)\n",
        "\n",
        "\n",
        "        if mask is not None:\n",
        "            #print(\"mask.shape, scaled_sims.shape\",mask.shape, scaled_sims.shape )\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "CNBTcs7nfMxJ"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids):\n",
        "\n",
        "        device = self.we.weight.device  # ensure all tensors follow this device\n",
        "\n",
        "        token_ids = token_ids.to(device)\n",
        "        word_embeddings = self.we(token_ids)\n",
        "\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "\n",
        "        self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=None)\n",
        "\n",
        "\n",
        "        residual_connection_values = self.layernorm(position_encoded + self_attention_values)\n",
        "\n",
        "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
        "\n",
        "        return residual_connection_values, residual_connection_values\n"
      ],
      "metadata": {
        "id": "QiXmZbOgf7xn"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "        ## NOTE: In this simple example, we are just using a \"single layer\" decoder.\n",
        "        ##       If we wanted to have multiple layers of decoder, then we would\n",
        "        ##       take the output of one decoder module and use it as input to\n",
        "        ##       the next module.\n",
        "\n",
        "        self.we = nn.Embedding(num_embeddings=num_tokens,\n",
        "                               embedding_dim=d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model=d_model,\n",
        "                                   max_len=max_len)\n",
        "\n",
        "        self.self_attention = Attention(d_model=d_model)\n",
        "        self.cross_attention = Attention(d_model=d_model)\n",
        "        self.layernorm1 = nn.LayerNorm(d_model)\n",
        "        self.layernorm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, token_ids,encoder_k, encoder_v):\n",
        "\n",
        "        token_ids = token_ids.to(self.we.weight.device)\n",
        "        word_embeddings = self.we(token_ids)\n",
        "        position_encoded = self.pe(word_embeddings)\n",
        "        if token_ids.dim() == 2:\n",
        "          mask = torch.tril(torch.ones((token_ids.size(1), token_ids.size(1))))\n",
        "          mask = mask.unsqueeze(0).expand(token_ids.size(0), -1, -1)  # [batch_size, seq_len, seq_len]\n",
        "        elif token_ids.dim() == 1:\n",
        "          mask = torch.tril(torch.ones((token_ids.size(0), token_ids.size(0))))\n",
        "        #mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=1))))\n",
        "        mask = mask == 0\n",
        "        mask = mask.to(self.we.weight.device)\n",
        "\n",
        "        mask_self_attention_values = self.self_attention(position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    position_encoded,\n",
        "                                                    mask=mask)\n",
        "\n",
        "        residual_connection_values = self.layernorm1(position_encoded + mask_self_attention_values)\n",
        "        x_cross_att = self.cross_attention(residual_connection_values, encoder_k, encoder_v, mask=None)\n",
        "        x = self.layernorm2(residual_connection_values + x_cross_att)\n",
        "        fc_layer_output = self.fc_layer(x)\n",
        "\n",
        "\n",
        "\n",
        "        return fc_layer_output\n"
      ],
      "metadata": {
        "id": "xIRWAdRHgDAf"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## First, create a model from DecoderOnlyTransformer()\n",
        "model = Encoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "\n",
        "\n",
        "## Now create the input for the transformer...\n",
        "question_test = pairs[20][0]\n",
        "print(question_test)\n",
        "mapped_values = [word_map[word] for word in question_test]\n",
        "encoder_input = torch.tensor(mapped_values)\n",
        "print(\"encoder_input\", encoder_input.shape)\n",
        "\n",
        "## Now get get predictions from the model\n",
        "encoder_k, encoder_v = model(encoder_input)\n",
        "answer_test = pairs[20][1]\n",
        "print(answer_test)\n",
        "mapped_values = [word_map['<start>']]+[word_map[word] for word in answer_test]\n",
        "decoder_input = torch.tensor(mapped_values)\n",
        "print(\"decoder_input\", decoder_input.shape)\n",
        "decoder = Decoder(num_tokens=len(word_map), d_model=2, max_len=25)\n",
        "output = decoder(decoder_input, encoder_k, encoder_v)\n",
        "\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "BppoaYtDgjl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e8ed6f-4a97-4307-973b-e972f7748a1f"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'really', 'really', 'really', 'wanna', 'go', 'but', 'i', 'cant', 'not', 'unless', 'my', 'sister', 'goes']\n",
            "encoder_input torch.Size([14])\n",
            "['im', 'workin', 'on', 'it', 'but', 'she', 'doesnt', 'seem', 'to', 'be', 'goin', 'for', 'him']\n",
            "decoder_input torch.Size([14])\n",
            "tensor([[-0.4964,  0.2904, -0.1212,  ..., -0.9225, -1.0401, -0.6083],\n",
            "        [-0.4964,  0.2904, -0.1212,  ..., -0.9225, -1.0401, -0.6083],\n",
            "        [ 1.3878,  0.0742, -0.4859,  ...,  0.8007,  1.1834, -0.4836],\n",
            "        ...,\n",
            "        [ 1.3878,  0.0742, -0.4859,  ...,  0.8007,  1.1834, -0.4836],\n",
            "        [-0.4964,  0.2904, -0.1212,  ..., -0.9225, -1.0401, -0.6083],\n",
            "        [-0.4964,  0.2904, -0.1212,  ..., -0.9225, -1.0401, -0.6083]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "num_tokens = len(word_map)\n",
        "d_model = 2\n",
        "max_len = 25\n",
        "batch_size = 32\n",
        "num_epochs = 200\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "6KYuFoGRmJMO"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the transformer model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_tokens, d_model, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "        self.decoder = Decoder(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "        # Output projection layer\n",
        "        self.output_linear = nn.Linear(num_tokens, num_tokens)\n",
        "\n",
        "    def forward(self, src_tokens, tgt_tokens):\n",
        "        # Pass source tokens through encoder\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "        # Pass target tokens and encoder outputs through decoder\n",
        "        decoder_output = self.decoder(tgt_tokens, encoder_output, encoder_hidden)\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "    def generate(self, src_tokens, max_len=10, start_token=4): # 4 is\n",
        "        device = src_tokens.device\n",
        "\n",
        "\n",
        "        # Encode the source sequence\n",
        "        encoder_output, encoder_hidden = self.encoder(src_tokens)\n",
        "\n",
        "        # Initialize decoder input with start token\n",
        "        decoder_input = torch.tensor([word_map['']])#+[word_map['<pad>']] * (max_len - 1))\n",
        "        decoder_input = decoder_input.unsqueeze(0).to(device) #batch size\n",
        "\n",
        "\n",
        "        generated_sequence = ['']\n",
        "\n",
        "        # Generate tokens one by one\n",
        "        for iter in range(max_len):\n",
        "            #print(f\"Iteration {iter}\")\n",
        "            # Get decoder output\n",
        "            decoder_output = self.decoder(decoder_input, encoder_output, encoder_hidden)\n",
        "            decoder_output = decoder_output.squeeze(0)\n",
        "            print(decoder_output)\n",
        "\n",
        "\n",
        "            # Get the predicted token\n",
        "            _, topi = decoder_output[-1].topk(1)\n",
        "            predicted_token = topi.item()\n",
        "            predicted_token= torch.tensor(predicted_token).to(device)\n",
        "            predicted_token_word = key = next((k for k, v in word_map.items() if v == predicted_token.item()), None)\n",
        "            # Add to the generated sequence\n",
        "            generated_sequence.append(predicted_token_word)\n",
        "\n",
        "\n",
        "            # Stop if we generated an  token\n",
        "            if predicted_token == word_map['<end>']:\n",
        "                break\n",
        "\n",
        "            # Update decoder input\n",
        "            predicted_token = predicted_token.view(1, 1)\n",
        "            decoder_input = torch.cat([decoder_input, predicted_token], dim=1)\n",
        "\n",
        "        return generated_sequence\n"
      ],
      "metadata": {
        "id": "uRptHOJemrlG"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Transformer(num_tokens=num_tokens, d_model=d_model, max_len=max_len)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1jo2SK7bm3_g"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2zzTgKflXYM",
        "outputId": "c4530970-883a-4dae-f132-00c372f190e0"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (we): Embedding(18244, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18244, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (we): Embedding(18244, 2)\n",
              "    (pe): PositionEncoding()\n",
              "    (self_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (cross_attention): Attention(\n",
              "      (W_q): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_k): Linear(in_features=2, out_features=2, bias=False)\n",
              "      (W_v): Linear(in_features=2, out_features=2, bias=False)\n",
              "    )\n",
              "    (layernorm1): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (layernorm2): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
              "    (fc_layer): Linear(in_features=2, out_features=18244, bias=True)\n",
              "  )\n",
              "  (output_linear): Linear(in_features=18244, out_features=18244, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    training_loss=[]\n",
        "    validation_loss=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        print(f\"\\n🌟 Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training loop\n",
        "        for i, (src, tgt_in, tgt_out) in enumerate(train_loader):\n",
        "            try:\n",
        "                optimizer.zero_grad()\n",
        "                src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "                #print(f\"🔁 Training Iteration {i}\")\n",
        "\n",
        "                output = model(src, tgt_in)\n",
        "                output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                loss = criterion(output_flat, target_flat)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error at training iteration {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        training_loss.append(epoch_loss / len(train_loader))\n",
        "        print(f\"✅ Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for j, (src, tgt_in, tgt_out) in enumerate(val_loader):\n",
        "                try:\n",
        "                    src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "                    output = model(src, tgt_in)\n",
        "                    output_flat = output.contiguous().view(-1, num_tokens)\n",
        "                    target_flat = tgt_out.contiguous().view(-1)\n",
        "\n",
        "                    loss = criterion(output_flat, target_flat)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Error at validation iteration {j}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        validation_loss.append(avg_val_loss)\n",
        "        print(f\"🧪 Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        model.train()  # switch back to training mode\n",
        "    return training_loss, validation_loss\n"
      ],
      "metadata": {
        "id": "cs4Wx2IwpBlv"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "avg_train_loss, avg_val_loss=train()"
      ],
      "metadata": {
        "id": "IIhgMtZXqZ-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed933678-2bf5-481f-9cdd-30462b89ed92"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🌟 Epoch 1/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 1 Training Loss: 3.8465\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 1 Validation Loss: 2.6524\n",
            "\n",
            "🌟 Epoch 2/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 2 Training Loss: 2.6248\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 2 Validation Loss: 2.6400\n",
            "\n",
            "🌟 Epoch 3/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 3 Training Loss: 2.6112\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 3 Validation Loss: 2.6209\n",
            "\n",
            "🌟 Epoch 4/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 4 Training Loss: 2.5367\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 4 Validation Loss: 2.5381\n",
            "\n",
            "🌟 Epoch 5/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 5 Training Loss: 2.5121\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 5 Validation Loss: 2.5346\n",
            "\n",
            "🌟 Epoch 6/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 6 Training Loss: 2.5079\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 6 Validation Loss: 2.5315\n",
            "\n",
            "🌟 Epoch 7/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 7 Training Loss: 2.5044\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 7 Validation Loss: 2.5268\n",
            "\n",
            "🌟 Epoch 8/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 8 Training Loss: 2.4983\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 8 Validation Loss: 2.5234\n",
            "\n",
            "🌟 Epoch 9/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 9 Training Loss: 2.4940\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 9 Validation Loss: 2.5192\n",
            "\n",
            "🌟 Epoch 10/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 10 Training Loss: 2.4883\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 10 Validation Loss: 2.5089\n",
            "\n",
            "🌟 Epoch 11/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 11 Training Loss: 2.4746\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 11 Validation Loss: 2.4969\n",
            "\n",
            "🌟 Epoch 12/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 12 Training Loss: 2.4656\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 12 Validation Loss: 2.4848\n",
            "\n",
            "🌟 Epoch 13/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 13 Training Loss: 2.4513\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 13 Validation Loss: 2.4736\n",
            "\n",
            "🌟 Epoch 14/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 14 Training Loss: 2.4371\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 14 Validation Loss: 2.4579\n",
            "\n",
            "🌟 Epoch 15/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 15 Training Loss: 2.4234\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 15 Validation Loss: 2.4460\n",
            "\n",
            "🌟 Epoch 16/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 16 Training Loss: 2.4065\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 16 Validation Loss: 2.4233\n",
            "\n",
            "🌟 Epoch 17/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 17 Training Loss: 2.3832\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 17 Validation Loss: 2.4043\n",
            "\n",
            "🌟 Epoch 18/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 18 Training Loss: 2.3604\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 18 Validation Loss: 2.3755\n",
            "\n",
            "🌟 Epoch 19/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 19 Training Loss: 2.3337\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 19 Validation Loss: 2.3451\n",
            "\n",
            "🌟 Epoch 20/20\n",
            "❌ Error at training iteration 4423: The size of tensor a (25) must match the size of tensor b (13) at non-singleton dimension 1\n",
            "✅ Epoch 20 Training Loss: 2.3021\n",
            "❌ Error at validation iteration 1832: The size of tensor a (25) must match the size of tensor b (17) at non-singleton dimension 1\n",
            "🧪 Epoch 20 Validation Loss: 2.3099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"transformer.pth\")\n",
        "model.load_state_dict(torch.load(\"transformer.pth\"))"
      ],
      "metadata": {
        "id": "xq019pzytSwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_losses(train_losses, val_losses):\n",
        "    epochs = list(range(1, len(train_losses) + 1))\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4ouVGB4BVc7E"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_input = torch.tensor([[word_map['your'], word_map['test'], word_map['sequence']]], device=device)\n",
        "    output_tokens = model.generate(test_input, max_len=20, start_token=word_map['<start>'])\n",
        "    print(output_tokens)\n",
        "    print(\"Generated:\", ' '.join([tok for tok in output_tokens if tok not in ['<pad>', '<end>', '<start>', None]]))"
      ],
      "metadata": {
        "id": "Pneq9omSlsju",
        "outputId": "c5761f55-0457-41b1-e909-fc4bb501ed1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(avg_train_loss, avg_val_loss)"
      ],
      "metadata": {
        "id": "5f-PsP2oVkQv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "b30d7cf3-df91-4a3f-9bda-9c9bf11ee431"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (src, tgt_in, tgt_out) in enumerate(test_loader):\n",
        "  src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "  response =model.generate(src, max_len=25, start_token=word_map[\"<start>\"])\n",
        "  sentence = []\n",
        "  for token in response:\n",
        "    if token == '<end>':\n",
        "        break\n",
        "    if token != '<pad>':\n",
        "        sentence.append(token)\n",
        "\n",
        "  # Join into sentence\n",
        "  print(sentence)\n",
        "  final_sentence = ' '.join(sentence).strip()\n",
        "  print(final_sentence)\n",
        "\n"
      ],
      "metadata": {
        "id": "wr2SJYjltdjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f4610656-479f-4846-d351-97de273cf713"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n",
            "['']\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-0106810d8c0f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<start>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-136-9ab966cd7b3e>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, src_tokens, max_len, start_token)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mpredicted_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mpredicted_token\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mpredicted_token_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredicted_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Add to the generated sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_token_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-136-9ab966cd7b3e>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mpredicted_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mpredicted_token\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mpredicted_token_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredicted_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Add to the generated sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_token_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}